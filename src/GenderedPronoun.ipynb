{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 11)\n",
      "(2000, 27)\n",
      "Val Acc = 0.431718061674\n",
      "Train Acc = 0.5885\n",
      "                    ID  A  B  NEITHER\n",
      "0        development-1  1  0        0\n",
      "1        development-2  1  0        0\n",
      "2        development-3  1  0        0\n",
      "3        development-4  0  1        0\n",
      "4        development-5  0  0        0\n",
      "5        development-6  0  1        0\n",
      "6        development-7  1  0        0\n",
      "7        development-8  0  1        0\n",
      "8        development-9  0  1        0\n",
      "9       development-10  1  0        0\n",
      "10      development-11  1  0        0\n",
      "11      development-12  1  0        0\n",
      "12      development-13  1  0        0\n",
      "13      development-14  0  1        0\n",
      "14      development-15  0  1        0\n",
      "15      development-16  0  0        0\n",
      "16      development-17  1  0        0\n",
      "17      development-18  0  0        0\n",
      "18      development-19  0  1        0\n",
      "19      development-20  0  0        0\n",
      "20      development-21  0  1        0\n",
      "21      development-22  1  0        0\n",
      "22      development-23  0  1        0\n",
      "23      development-24  0  0        0\n",
      "24      development-25  0  1        0\n",
      "25      development-26  0  1        0\n",
      "26      development-27  1  0        0\n",
      "27      development-28  0  1        0\n",
      "28      development-29  0  1        0\n",
      "29      development-30  1  0        0\n",
      "...                ... .. ..      ...\n",
      "1970  development-1971  0  1        0\n",
      "1971  development-1972  1  0        0\n",
      "1972  development-1973  0  1        0\n",
      "1973  development-1974  0  1        0\n",
      "1974  development-1975  0  0        0\n",
      "1975  development-1976  0  0        0\n",
      "1976  development-1977  0  0        0\n",
      "1977  development-1978  0  1        0\n",
      "1978  development-1979  0  1        0\n",
      "1979  development-1980  1  0        0\n",
      "1980  development-1981  1  0        0\n",
      "1981  development-1982  0  1        0\n",
      "1982  development-1983  0  1        0\n",
      "1983  development-1984  0  0        0\n",
      "1984  development-1985  0  1        0\n",
      "1985  development-1986  0  0        1\n",
      "1986  development-1987  0  1        0\n",
      "1987  development-1988  1  0        0\n",
      "1988  development-1989  0  1        0\n",
      "1989  development-1990  0  1        0\n",
      "1990  development-1991  0  0        0\n",
      "1991  development-1992  0  1        0\n",
      "1992  development-1993  0  0        0\n",
      "1993  development-1994  0  1        0\n",
      "1994  development-1995  1  0        0\n",
      "1995  development-1996  1  0        0\n",
      "1996  development-1997  0  1        0\n",
      "1997  development-1998  0  1        0\n",
      "1998  development-1999  1  0        0\n",
      "1999  development-2000  1  0        0\n",
      "\n",
      "[2000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#Adjust the paths\n",
    "dev_data_path = 'D:\\Kaggle\\GenderedPronoun\\gap-coreference-master\\gap-coreference-master\\gap-development.tsv'\n",
    "val_data_path = 'D:\\Kaggle\\GenderedPronoun\\gap-coreference-master\\gap-coreference-master\\gap-validation.tsv'\n",
    "\n",
    "output_file_path = 'D:\\Kaggle\\GenderedPronoun\\gap-coreference-master\\gap-coreference-master\\output.csv'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#Read data from csv\n",
    "train_set = pd.read_csv(dev_data_path,sep='\\t')\n",
    "val_set = pd.read_csv(val_data_path,sep='\\t')\n",
    "labelNames = ['A-distance','B-distance','Pronoun-at-start', 'A-before', 'B-before', 'A-after', 'B-after',\n",
    "              'dot-betweenA', 'dot-betweenB', 'comma-betweenA','comma-betweenB', 'Pronoun-gender', 'Pronoun-singular',\n",
    "             'Pronoun-count-sentenceA', 'Pronoun-count-sentenceB']\n",
    "\n",
    "PRONOUN_MAP = {\n",
    "    'their': '0',\n",
    "    'they': '0',\n",
    "    'them': '0',\n",
    "    'her': '1',\n",
    "    'hers':'1',\n",
    "    'she': '1',\n",
    "    'his': '-1',\n",
    "    'him': '-1',\n",
    "    'he': '-1',\n",
    "}\n",
    "\n",
    "def getSentanceContainingIndex(row, colName):\n",
    "    idx = row[colName]\n",
    "    string = str(row['Text'])\n",
    "    sentance_start = string.rfind('.', 0, idx)\n",
    "    sentance_end =   string.find('.', idx, len(string))\n",
    "    \n",
    "    if sentance_start == -1:\n",
    "        sentance_start = 0\n",
    "    if sentance_end == -1:\n",
    "        sentance_end = len(string)\n",
    "        \n",
    "    result =str(row['Text'][sentance_start:sentance_end])\n",
    "    return result\n",
    "    \n",
    "def getPronounCount(row, colName):\n",
    "    sentence = getSentanceContainingIndex(row, colName)\n",
    "    count = sentence.count(row['Pronoun'])\n",
    "    return count\n",
    "    \n",
    "def frameSubStrContains(my_set, minIdx, maxIdx, searchSubstr):\n",
    "    contains=[]\n",
    "    for index, row in maxIdx.iteritems():\n",
    "        subStr = my_set['Text'][index][minIdx[index]: maxIdx[index]]\n",
    "        contains.append(searchSubstr in subStr)\n",
    "\n",
    "    return contains\n",
    "            \n",
    "def prepareData(my_set):\n",
    "    #Compute Distance from pronoun to each name\n",
    "    my_set['A-distance'] = abs(my_set['A-offset'] - my_set['Pronoun-offset']);\n",
    "    my_set['B-distance'] = abs(my_set['B-offset'] - my_set['Pronoun-offset']);\n",
    "    \n",
    "    my_set['Pronoun-at-start'] = my_set['Pronoun-offset'] == 0\n",
    "   \n",
    "    my_set['A-before'] = my_set['Pronoun-offset'] < my_set['A-offset']\n",
    "    my_set['B-before'] = my_set['Pronoun-offset'] < my_set['B-offset']\n",
    "    \n",
    "    my_set['A-after'] = my_set['Pronoun-offset'] > my_set['A-offset']\n",
    "    my_set['B-after'] = my_set['Pronoun-offset'] > my_set['B-offset']\n",
    "   \n",
    "    max_a_offset = my_set[['A-offset','Pronoun-offset' ]].max(axis=1)\n",
    "    min_a_offset = my_set[['A-offset','Pronoun-offset' ]].min(axis=1)\n",
    "    max_b_offset = my_set[['B-offset','Pronoun-offset' ]].max(axis=1)\n",
    "    min_b_offset = my_set[['B-offset','Pronoun-offset' ]].min(axis=1)\n",
    "    \n",
    "    my_set['dot-betweenA'] = pd.DataFrame(frameSubStrContains(my_set, min_a_offset, max_a_offset, '.'))\n",
    "    my_set['comma-betweenA'] = pd.DataFrame(frameSubStrContains(my_set, min_a_offset, max_a_offset, ','))\n",
    "\n",
    "    my_set['dot-betweenB'] = pd.DataFrame(frameSubStrContains(my_set, min_b_offset, max_b_offset, '.'))\n",
    "    my_set['comma-betweenB'] = pd.DataFrame(frameSubStrContains(my_set, min_b_offset, max_b_offset, ','))\n",
    "    \n",
    "    pro_gender = []\n",
    "    pro_singular = []\n",
    "    for index, row in my_set['Pronoun'].iteritems():\n",
    "        pro_gender.append(PRONOUN_MAP[my_set['Pronoun'][index].lower()])\n",
    "        pro_singular.append(PRONOUN_MAP[my_set['Pronoun'][index].lower()] == 0)\n",
    "    \n",
    "    my_set['Pronoun-gender'] = pd.DataFrame(pro_gender)\n",
    "    my_set['Pronoun-singular'] = pd.DataFrame(pro_singular) \n",
    "    \n",
    "    my_set['Pronoun-count-sentenceA'] = pd.DataFrame(my_set.apply(getPronounCount,  args=('A-offset',), axis=1))\n",
    "    my_set['Pronoun-count-sentenceB'] = pd.DataFrame(my_set.apply(getPronounCount,  args=('B-offset',), axis=1))\n",
    "\n",
    "    #print(\"GENDER\", pro_singular)\n",
    "    #Convert from the provided labels in data set to the Kaggle labels format\n",
    "    my_set['A'] = np.where(my_set['A-coref']==True, 1, 0)\n",
    "    my_set['B'] = np.where(my_set['B-coref']==True, 1, 0)\n",
    "    my_set['NEITHER'] = np.where((my_set['A-coref']==False) & (my_set['B-coref']==False), 1, 0)\n",
    "    \n",
    "\n",
    "print(train_set.shape)\n",
    "prepareData(train_set)\n",
    "prepareData(val_set)\n",
    "print(train_set.shape)\n",
    "\n",
    "#Compute probability from the distance directly without ML\n",
    "#train_set['A'] = train_set['A-distance']/(train_set['A-distance']+train_set['B-distance'])\n",
    "#train_set['B'] = train_set['B-distance']/(train_set['A-distance']+train_set['B-distance'])\n",
    "#train_set['NEITHER'] = 0\n",
    "#print(rd)\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=5)\n",
    "X = train_set[labelNames]\n",
    "Y = train_set[['A','B','NEITHER']]\n",
    "neigh.fit(X, Y)\n",
    "\n",
    "P = val_set[labelNames]\n",
    "Z = val_set[['A','B','NEITHER']]\n",
    "res = neigh.predict(P)\n",
    "\n",
    "\n",
    "acc = accuracy_score(Z, res)\n",
    "\n",
    "print(\"Val Acc = \" + str(acc))\n",
    "\n",
    "P = train_set[labelNames]\n",
    "Z = train_set[['A','B','NEITHER']]\n",
    "res = neigh.predict(P)\n",
    "acc = accuracy_score(Z, res)\n",
    "print(\"Train Acc = \" + str(acc))\n",
    "\n",
    "df = pd.DataFrame(data=res,    # values\n",
    "              columns=['A','B','NEITHER'])\n",
    "\n",
    "df.insert(loc=0, column='ID', value=train_set['ID'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv(path_or_buf=output_file_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
